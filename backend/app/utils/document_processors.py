import asyncio
from pathlib import Path
from typing import Optional, List, Callable, Awaitable, Dict, Any
import aiofiles
import PyPDF2
import docx
import io
import base64
import tempfile
from pdf2image import convert_from_path
from PIL import Image
import logging
from zipfile import ZipFile
import httpx

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


def _extract_content_from_response(data: Dict[str, Any]) -> str:
    """Extrait le contenu textuel d'une r√©ponse de type OpenAI."""
    try:
        message_content = data.get("choices", [])[0].get("message", {}).get("content", "")
    except Exception:
        return ""

    if isinstance(message_content, list):
        parts: List[str] = []
        for part in message_content:
            if isinstance(part, dict):
                text_value = part.get("text")
                if text_value:
                    parts.append(str(text_value))
            elif part is not None:
                parts.append(str(part))
        return "".join(parts)

    return str(message_content) if message_content is not None else ""


async def _call_vision_api(messages):
    """Appelle le mod√®le de vision configur√© en mode API."""
    from app.config import settings

    if not settings.vision_api_key:
        raise ValueError("VISION_API_KEY (ou MISTRAL_API_KEY) est requis pour le mod√®le de vision en mode API")

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {settings.vision_api_key}",
    }
    payload = {
        "model": settings.vision_model,
        "messages": messages,
    }

    try:
        async with httpx.AsyncClient(timeout=settings.vllm_timeout) as client:
            response = await client.post(settings.vision_api_url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
    except Exception as exc:
        logger.error("Erreur lors de l'appel du mod√®le de vision API: %s", exc)
        raise


MIN_SIGNIFICANT_IMAGE_AREA = 64000  # ‚âà 250x250 px


async def _emit_progress(
    callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]],
    payload: Dict[str, Any],
) -> None:
    if not callback:
        return
    try:
        await callback(payload)
    except Exception as exc:
        logger.debug("Progress callback raised an exception: %s", exc)

async def process_document_to_text(
    file_path: str,
    file_type: str,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """
    Convertit diff√©rents types de documents en texte brut
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        raise FileNotFoundError(f"Fichier non trouv√©: {file_path}")
    
    # D√©terminer le type de traitement selon le type MIME ou l'extension
    ext = file_path.suffix.lower()
    
    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.05,
            "message": "Pr√©paration de l'extraction",
        },
    )

    if ext in ['.txt', '.md']:
        content = await _process_text_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content
    elif ext == '.pdf' or 'pdf' in file_type:
        return await _process_pdf_file(file_path, progress_callback=progress_callback)
    elif ext in ['.docx', '.doc'] or 'word' in file_type:
        return await _process_docx_file(file_path, progress_callback=progress_callback)
    elif ext == '.rtf':
        content = await _process_rtf_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content
    elif ext in ['.png', '.jpg', '.jpeg', '.gif', '.webp'] or 'image' in file_type:
        return await _process_image_file_with_vision(file_path, progress_callback=progress_callback)
    else:
        # Par d√©faut, essayer de lire comme texte
        content = await _process_text_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content

async def _process_text_file(file_path: Path) -> str:
    """Lit un fichier texte"""
    async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        return await f.read()

async def _process_pdf_file(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Extrait le texte d'un PDF - utilise une approche hybride"""
    from app.config import settings
    
    # D'abord, essayer l'extraction de texte classique avec PyPDF2
    def extract_pdf_text():
        text = []
        has_images = False
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text() or ""

                if page_text.strip():
                    text.append(f"Page {page_num + 1}:\n{page_text}")
                else:
                    has_images = True

                # Inspecter les XObjects pour d√©tecter des images m√™me si on a d√©j√† du texte
                try:
                    resources = page.get("/Resources")
                    if resources is not None:
                        try:
                            resources = resources.get_object()
                        except Exception:
                            pass
                    if isinstance(resources, dict):
                        xobjects = resources.get("/XObject")
                        if xobjects is not None:
                            try:
                                xobjects_dict = xobjects.get_object()
                            except Exception:
                                xobjects_dict = xobjects
                            if isinstance(xobjects_dict, dict):
                                for obj in xobjects_dict.values():
                                    try:
                                        xobj = obj.get_object() if hasattr(obj, "get_object") else obj
                                        subtype = xobj.get("/Subtype")
                                    except Exception:
                                        continue
                                    if subtype == "/Image":
                                        width = xobj.get("/Width") or 0
                                        height = xobj.get("/Height") or 0
                                        try:
                                            area = int(width) * int(height)
                                        except Exception:
                                            area = 0
                                        if area >= MIN_SIGNIFICANT_IMAGE_AREA:
                                            has_images = True
                                            break
                                        logger.debug(
                                            "Ignoring small PDF image on page %d (%d px¬≤)",
                                            page_num + 1,
                                            area,
                                        )
                except Exception:
                    # Si l'inspection √©choue, on ne bloque pas le flux
                    pass
        return '\n'.join(text), has_images
    
    loop = asyncio.get_event_loop()
    extracted_text, has_potential_images = await loop.run_in_executor(None, extract_pdf_text)
    
    # Si le PDF semble contenir des images ou peu de texte, utiliser le mod√®le de vision
    if has_potential_images or len(extracted_text.strip()) < settings.pdf_use_vision_threshold:
        logger.info(
            "üìä PDF n√©cessite une analyse par le mod√®le de vision - Texte extrait: %d caract√®res (seuil: %d)",
            len(extracted_text.strip()),
            settings.pdf_use_vision_threshold,
        )
        if has_potential_images:
            logger.info("üñºÔ∏è Images d√©tect√©es dans le PDF")
        
        try:
            vision_text = await _process_pdf_with_vision(
                file_path,
                max_pages=settings.pdf_max_pages_vision,
                progress_callback=progress_callback,
            )
            # Combiner les deux approches si on a du texte des deux c√¥t√©s
            if extracted_text.strip() and vision_text.strip():
                logger.info("üîÄ Combinaison extraction texte + mod√®le de vision")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (VLM)",
                        "progress": 0.7,
                        "message": "Analyse visuelle termin√©e",
                    },
                )
                return (
                    "=== Analyse visuelle (VLM) ===\n"
                    f"{vision_text}\n\n"
                    "=== Texte extrait ===\n"
                    f"{extracted_text}"
                )
            elif vision_text.strip():
                logger.info("üé® Utilisation du mod√®le de vision seul")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (VLM)",
                        "progress": 0.7,
                        "message": "Analyse visuelle termin√©e",
                    },
                )
                return vision_text
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement PDF avec mod√®le de vision: {e}")
            # Fallback sur le texte extrait
    else:
        logger.info(f"üìù PDF trait√© avec extraction de texte simple ({len(extracted_text.strip())} caract√®res)")
    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.6,
            "message": "Extraction du texte PDF termin√©e",
        },
    )
    return extracted_text

async def _process_docx_file(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Extrait le texte d'un fichier DOCX et traite les images embarqu√©es"""

    def extract_docx_text() -> str:
        doc = docx.Document(file_path)
        text = []
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text.append(paragraph.text)
        return '\n'.join(text)

    loop = asyncio.get_event_loop()
    text_content = await loop.run_in_executor(None, extract_docx_text)

    image_sections: List[str] = []
    has_images = False

    try:
        with ZipFile(file_path, 'r') as archive:
            media_files = [name for name in archive.namelist() if name.startswith('word/media/')]
            if media_files:
                significant_images: List[tuple[str, bytes]] = []
                skipped_small = 0

                for name in media_files:
                    try:
                        data = archive.read(name)
                    except KeyError:
                        logger.warning(f"Image {name} introuvable dans l'archive DOCX")
                        continue

                    try:
                        with Image.open(io.BytesIO(data)) as pil_img:
                            width, height = pil_img.size
                            area = width * height
                    except Exception:
                        area = MIN_SIGNIFICANT_IMAGE_AREA  # Fallback: traiter

                    if area < MIN_SIGNIFICANT_IMAGE_AREA:
                        skipped_small += 1
                        logger.debug(
                            "Skipping small DOCX image %s (%d px¬≤)",
                            name,
                            area,
                        )
                        continue

                    significant_images.append((name, data))

                total_images = len(significant_images)
                has_images = total_images > 0

                if total_images == 0:
                    logger.info("Aucune image significative d√©tect√©e dans le DOCX")
                else:
                    progress_start = 0.2
                    progress_end = 0.7
                    progress_span = max(progress_end - progress_start, 0.05)
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (VLM)",
                            "current": 0,
                            "total": total_images,
                            "progress": progress_start,
                            "message": f"Analyse des images (0/{total_images})",
                        },
                    )

                    with tempfile.TemporaryDirectory() as temp_dir:
                        temp_dir_path = Path(temp_dir)
                        for idx, (name, data) in enumerate(significant_images, start=1):
                            suffix = Path(name).suffix or '.png'
                            image_path = temp_dir_path / f"docx_image_{idx}{suffix}"

                            try:
                                async with aiofiles.open(image_path, 'wb') as img_file:
                                    await img_file.write(data)
                            except Exception as e:
                                logger.error(f"‚ùå Impossible d'√©crire l'image DOCX {name}: {e}")
                                continue

                            try:
                                transcription = await _process_image_file_with_vision(
                                    image_path,
                                    progress_callback=progress_callback,
                                    position=idx,
                                    total=total_images,
                                )
                                if transcription and transcription.strip():
                                    image_sections.append(
                                        f"Image {idx} ({Path(name).name}):\n{transcription}"
                                    )
                                await _emit_progress(
                                    progress_callback,
                                    {
                                        "stage": "vision_analysis",
                                        "stage_label": "Analyse visuelle (VLM)",
                                        "current": idx,
                                        "total": total_images,
                                        "progress": progress_start + (idx / max(total_images, 1)) * progress_span,
                                        "message": f"Analyse des images ({idx}/{total_images})",
                                    },
                                )
                            except Exception as e:
                                logger.error(f"‚ùå Erreur lors de l'analyse du mod√®le de vision pour l'image DOCX {name}: {e}")

                if skipped_small:
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (VLM)",
                            "progress": progress_start,
                            "message": f"{skipped_small} image(s) ignor√©e(s) car trop petites",
                        },
                    )
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Impossible d'extraire les images du DOCX: {e}")

    if has_images and image_sections:
        await _emit_progress(
            progress_callback,
            {
                "stage": "vision_analysis",
                "stage_label": "Analyse visuelle (VLM)",
                "progress": 0.7,
                "message": "Analyse visuelle termin√©e",
            },
        )
        if text_content.strip():
            return (
                "=== Analyse visuelle (VLM) ===\n"
                + "\n\n".join(image_sections)
                + "\n\n=== Texte extrait ===\n"
                + text_content
            )
        return "\n\n".join(image_sections)

    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.6,
            "message": "Texte extrait",
        },
    )

    return text_content

async def _process_rtf_file(file_path: Path) -> str:
    """Traite un fichier RTF (simplifi√© - n√©cessiterait une lib sp√©cialis√©e pour un support complet)"""
    # Pour l'instant, traiter comme texte brut
    # Dans un cas r√©el, utiliser striprtf ou python-rtf
    return await _process_text_file(file_path)

async def _process_image_file_with_vision(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    position: Optional[int] = None,
    total: Optional[int] = None,
) -> str:
    """Analyse et transcrit le contenu d'une image via le mod√®le de vision."""
    from app.config import settings
    
    logger.info(f"üé® D√©but analyse vision pour: {file_path.name}")
    single_asset = position is None or total is None
    progress_start = 0.2 if single_asset else None
    progress_end = 0.7 if single_asset else None
    if single_asset:
        await _emit_progress(
            progress_callback,
            {
                "stage": "vision_analysis",
                "stage_label": "Analyse visuelle (VLM)",
                "current": 0,
                "total": 1,
                "progress": progress_start,
                "message": "Analyse visuelle de l'image",
            },
        )
    logger.info(f"üîß Mode LLM: {settings.llm_mode}")
    
    # Encoder l'image en base64
    logger.info(f"üîê Encodage de l'image en base64...")
    async with aiofiles.open(file_path, 'rb') as f:
        image_data = await f.read()
        base64_image = base64.b64encode(image_data).decode('utf-8')
    logger.info(f"‚úÖ Image encod√©e: {len(base64_image)} caract√®res")
    
    # D√©terminer le type MIME de l'image
    ext = file_path.suffix.lower()
    mime_types = {
        '.png': 'image/png',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }
    mime_type = mime_types.get(ext, 'image/jpeg')
    
    # D√©terminer si on utilise le mode API ou local
    if settings.llm_mode == "local":
        logger.info("üöÄ Utilisation du mod√®le de vision local (vLLM)")
        from app.services.vllm_service import VLLMService
        
        try:
            vllm_service = VLLMService()
            prompt = (
                "Analyse cette image avec le plus de pr√©cision possible. Commence par identifier le type de visuel "
                "(photo, illustration, capture d'√©cran, tableau, slide, document scann√©, etc.). "
                "Ensuite, retranscris mot pour mot tout le texte lisible. Pour un tableau ou un formulaire, "
                "restitue les en-t√™tes et les valeurs cellule par cellule. Pour une capture d'√©cran, explique "
                "l'application ou le site montr√©, les sections visibles et le d√©roul√© exact de la conversation ou des "
                "donn√©es affich√©es. Pour un paysage ou une sc√®ne photo, d√©cris en d√©tail les √©l√©ments, leurs positions, "
                "les couleurs, l'ambiance, ainsi que toute information contextuelle implicite (moment de la journ√©e, "
                "activit√© en cours, public vis√©, etc.). Termine par un r√©sum√© synth√©tique et les informations cl√©s √† "
                "retenir. Organise ta r√©ponse avec des sections claires (Type d'image, Texte exact, Description d√©taill√©e, "
                "R√©sum√©, Informations cl√©s)."
            )
            
            result = await vllm_service.process_image_with_vision_model(base64_image, prompt)
            logger.info(f"‚úÖ Mod√®le de vision local a retourn√© {len(result)} caract√®res")
            logger.info(f"üìÑ Aper√ßu: {result[:200]}...")
            await _emit_progress(
                progress_callback,
                {
                    "stage": "vision_analysis",
                    "stage_label": "Analyse visuelle (VLM)",
                    "current": position or 1,
                    "total": total or 1,
                    "progress": progress_end,
                    "message": "Analyse visuelle termin√©e",
                },
            )
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur mod√®le de vision local: {str(e)}", exc_info=True)
            return f"Erreur lors de l'analyse de l'image avec le mod√®le de vision local: {str(e)}"
    else:
        logger.info(f"üöÄ Appel API vision avec mod√®le: {settings.vision_model}")
        image_url = f"data:{mime_type};base64,{base64_image}"
        
        try:
            response = await _call_vision_api(
                [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """Analyse cette image et fais une transcription compl√®te et d√©taill√©e de son contenu. 
                                Si l'image contient du texte, transcris-le exactement. 
                                Si l'image contient des √©l√©ments visuels (graphiques, sch√©mas, photos), d√©cris-les de mani√®re d√©taill√©e.
                                Si c'est une capture d'√©cran, d√©cris l'interface et transcris tout le texte visible.
                                Organise ta r√©ponse de mani√®re structur√©e."""
                            },
                            {
                                "type": "image_url",
                                "image_url": image_url
                            }
                        ]
                    }
                ]
            )
            
            result = _extract_content_from_response(response)
            if result:
                logger.info(f"‚úÖ Mod√®le de vision API a retourn√© {len(result)} caract√®res")
                logger.info(f"üìÑ Aper√ßu: {result[:200]}...")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (VLM)",
                        "current": position or 1,
                        "total": total or 1,
                        "progress": progress_end,
                        "message": "Analyse visuelle termin√©e",
                    },
                )
                return result
            logger.error("‚ùå Le mod√®le de vision API n'a retourn√© aucune r√©ponse")
            return "Erreur: Aucune transcription g√©n√©r√©e par le mod√®le de vision"
            
        except Exception as e:
            logger.error(f"‚ùå Erreur mod√®le de vision (API): {str(e)}", exc_info=True)
            return f"Erreur lors de l'analyse de l'image avec le mod√®le de vision: {str(e)}"

async def _process_pdf_with_vision(
    file_path: Path,
    max_pages: int = 0,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Convertit les pages PDF en images et les analyse avec le mod√®le de vision"""
    from app.config import settings
    
    logger.info(f"üìë D√©but traitement PDF avec mod√®le de vision: {file_path.name}")
    logger.info(f"üîß Mode LLM: {settings.llm_mode}")
    
    # Initialiser le service appropri√© selon le mode
    if settings.llm_mode == "local":
        from app.services.vllm_service import VLLMService
        vllm_service = VLLMService()
        logger.info("üìä Utilisation du mod√®le de vision local pour PDF")
    else:
        logger.info(f"üìä Utilisation du mod√®le de vision API pour PDF (mod√®le: {settings.vision_model})")
    
    results = []
    
    # Cr√©er un dossier temporaire pour les images
    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            # Convertir le PDF en images (limit√©es √† max_pages pour √©viter de traiter des PDFs √©normes)
            if max_pages > 0:
                logger.info(f"üñºÔ∏è Conversion PDF en images (max {max_pages} pages)...")
                convert_kwargs = {"first_page": 1, "last_page": max_pages, "dpi": 150}
            else:
                logger.info("üñºÔ∏è Conversion PDF en images (toutes les pages)...")
                convert_kwargs = {"dpi": 150}
            images = await asyncio.to_thread(
                convert_from_path,
                str(file_path),
                **convert_kwargs,
            )
            total_pages = len(images)
            logger.info(f"‚úÖ {total_pages} pages converties")
            progress_start = 0.2
            progress_end = 0.7
            progress_span = max(progress_end - progress_start, 0.05)
            await _emit_progress(
                progress_callback,
                {
                    "stage": "vision_analysis",
                    "stage_label": "Analyse visuelle (VLM)",
                    "current": 0,
                    "total": total_pages,
                    "progress": progress_start,
                    "message": f"Analyse des pages (0/{total_pages})",
                },
            )
            
            # Traiter chaque page avec le mod√®le de vision
            for i, image in enumerate(images):
                logger.info(f"üìÑ Traitement page {i+1}/{total_pages}...")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (VLM)",
                        "current": i,
                        "total": total_pages,
                        "progress": progress_start + (i / max(total_pages, 1)) * progress_span,
                        "message": f"Analyse de la page {i+1}/{total_pages}",
                    },
                )
                # Sauvegarder temporairement l'image
                temp_image_path = Path(temp_dir) / f"page_{i+1}.png"
                await asyncio.to_thread(image.save, str(temp_image_path), 'PNG')
                
                # Encoder en base64
                async with aiofiles.open(temp_image_path, 'rb') as f:
                    image_data = await f.read()
                    base64_image = base64.b64encode(image_data).decode('utf-8')
                
                # Analyser avec le mod√®le de vision (API ou local selon le mode)
                try:
                    prompt = (
                        f"Analyse la page {i+1} de ce PDF en suivant les directives suivantes : identifie d'abord le type de "
                        "contenu visuel principal (document imprim√©, capture d'√©cran, diapositive, photo, tableau, etc.). "
                        "Transcris ensuite mot pour mot tout le texte lisible. Pour les tableaux, restitue les colonnes et "
                        "les lignes avec leurs valeurs exactes. Pour les captures d'√©cran, explique le contexte (application, "
                        "sites ou interlocuteurs) et d√©taille la conversation ou les donn√©es affich√©es. Pour les photos ou "
                        "illustrations, d√©cris pr√©cis√©ment les √©l√©ments visibles, leurs positions, couleurs, ambiance et "
                        "intention probable. Termine la page par un r√©sum√© synth√©tique et une liste d'informations cl√©s √† "
                        "retenir. Structure ta r√©ponse avec les sections : Type de contenu, Texte exact, Description "
                        "d√©taill√©e, R√©sum√©, Informations cl√©s."
                    )
                    
                    page_content: Optional[str] = None

                    if settings.llm_mode == "local":
                        page_content = await vllm_service.process_image_with_vision_model(base64_image, prompt)
                    else:
                        image_url = f"data:image/png;base64,{base64_image}"
                        response = await _call_vision_api(
                            [
                                {
                                    "role": "user",
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": prompt
                                        },
                                        {
                                            "type": "image_url",
                                            "image_url": image_url
                                        }
                                    ]
                                }
                            ]
                        )
                        page_content = _extract_content_from_response(response)

                    if page_content:
                        results.append(f"\n=== Page {i+1} ===\n{page_content}")
                    else:
                        logger.warning("Le mod√®le de vision n'a renvoy√© aucun contenu pour la page %d", i + 1)
                        raise RuntimeError("La r√©ponse du mod√®le de vision est vide")

                except Exception as e:
                    results.append(f"\n=== Page {i+1} ===\nErreur lors de l'analyse: {str(e)}")
                finally:
                    current_page = min(i + 1, total_pages)
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (VLM)",
                            "current": current_page,
                            "total": total_pages,
                            "progress": progress_start + (current_page / max(total_pages, 1)) * progress_span,
                            "message": f"Analyse des pages ({current_page}/{total_pages})",
                        },
                    )
                
                # Limiter pour √©viter de surcharger l'API
                if max_pages > 0 and i >= max_pages - 1:
                    if len(images) > max_pages:
                        results.append(f"\n\n[Note: PDF contient {len(images)} pages, seules les {max_pages} premi√®res ont √©t√© analys√©es]")
                    break
                    
        except Exception as e:
            return f"Erreur lors de la conversion PDF en images: {str(e)}"

    await _emit_progress(
        progress_callback,
        {
            "stage": "vision_analysis",
            "stage_label": "Analyse visuelle (VLM)",
            "progress": 0.7,
            "message": "Analyse visuelle termin√©e",
        },
    )
    
    return '\n'.join(results)

def estimate_token_count(text: str) -> int:
    """
    Estime le nombre de tokens dans un texte
    Approximation: ~4 caract√®res par token en moyenne
    """
    return len(text) // 4

def truncate_to_token_limit(text: str, max_tokens: int = 2000) -> str:
    """
    Tronque un texte pour respecter une limite de tokens
    """
    estimated_chars = max_tokens * 4
    if len(text) <= estimated_chars:
        return text
    
    # Tronquer en gardant un peu de marge
    truncated = text[:estimated_chars - 100]
    
    # Essayer de couper √† la fin d'une phrase
    last_period = truncated.rfind('.')
    last_newline = truncated.rfind('\n')
    
    cut_point = max(last_period, last_newline)
    if cut_point > estimated_chars // 2:  # Si on trouve un point de coupure raisonnable
        truncated = truncated[:cut_point + 1]
    
    return truncated + "\n\n[Document tronqu√©...]"
