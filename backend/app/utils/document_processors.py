import asyncio
from pathlib import Path
from typing import Optional, List, Callable, Awaitable, Dict, Any
import aiofiles
import PyPDF2
import docx
import io
import base64
from mistralai import Mistral
import os
import tempfile
from pdf2image import convert_from_path
from PIL import Image
import logging
from zipfile import ZipFile


async def _call_pixtral_api(messages):
    """Appelle le modÃ¨le Pixtral avec fallback si le modÃ¨le configurÃ© est invalide."""
    from app.config import settings

    client = Mistral(api_key=settings.mistral_api_key)
    preferred_model = settings.pixtral_model
    fallback_model = "pixtral-large-latest"

    async def _invoke(model_name: str):
        return await asyncio.to_thread(
            client.chat.complete,
            model=model_name,
            messages=messages,
        )

    try:
        return await _invoke(preferred_model)
    except Exception as e:
        message = str(e)
        if "invalid_model" in message and preferred_model != fallback_model:
            logger.warning(
                "â— ModÃ¨le Pixtral %s invalide, tentative avec fallback %s",
                preferred_model,
                fallback_model,
            )
            return await _invoke(fallback_model)
        raise

# Configurer le logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


MIN_SIGNIFICANT_IMAGE_AREA = 64000  # â‰ˆ 250x250 px


async def _emit_progress(
    callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]],
    payload: Dict[str, Any],
) -> None:
    if not callback:
        return
    try:
        await callback(payload)
    except Exception as exc:
        logger.debug("Progress callback raised an exception: %s", exc)

async def process_document_to_text(
    file_path: str,
    file_type: str,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """
    Convertit diffÃ©rents types de documents en texte brut
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        raise FileNotFoundError(f"Fichier non trouvÃ©: {file_path}")
    
    # DÃ©terminer le type de traitement selon le type MIME ou l'extension
    ext = file_path.suffix.lower()
    
    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.05,
            "message": "PrÃ©paration de l'extraction",
        },
    )

    if ext in ['.txt', '.md']:
        content = await _process_text_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content
    elif ext == '.pdf' or 'pdf' in file_type:
        return await _process_pdf_file(file_path, progress_callback=progress_callback)
    elif ext in ['.docx', '.doc'] or 'word' in file_type:
        return await _process_docx_file(file_path, progress_callback=progress_callback)
    elif ext == '.rtf':
        content = await _process_rtf_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content
    elif ext in ['.png', '.jpg', '.jpeg', '.gif', '.webp'] or 'image' in file_type:
        return await _process_image_file_with_pixtral(file_path, progress_callback=progress_callback)
    else:
        # Par dÃ©faut, essayer de lire comme texte
        content = await _process_text_file(file_path)
        await _emit_progress(
            progress_callback,
            {
                "stage": "text_extraction",
                "stage_label": "Extraction du texte",
                "progress": 0.6,
                "message": "Texte extrait",
            },
        )
        return content

async def _process_text_file(file_path: Path) -> str:
    """Lit un fichier texte"""
    async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        return await f.read()

async def _process_pdf_file(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Extrait le texte d'un PDF - utilise une approche hybride"""
    from app.config import settings
    
    # D'abord, essayer l'extraction de texte classique avec PyPDF2
    def extract_pdf_text():
        text = []
        has_images = False
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text() or ""

                if page_text.strip():
                    text.append(f"Page {page_num + 1}:\n{page_text}")
                else:
                    has_images = True

                # Inspecter les XObjects pour dÃ©tecter des images mÃªme si on a dÃ©jÃ  du texte
                try:
                    resources = page.get("/Resources")
                    if resources is not None:
                        try:
                            resources = resources.get_object()
                        except Exception:
                            pass
                    if isinstance(resources, dict):
                        xobjects = resources.get("/XObject")
                        if xobjects is not None:
                            try:
                                xobjects_dict = xobjects.get_object()
                            except Exception:
                                xobjects_dict = xobjects
                            if isinstance(xobjects_dict, dict):
                                for obj in xobjects_dict.values():
                                    try:
                                        xobj = obj.get_object() if hasattr(obj, "get_object") else obj
                                        subtype = xobj.get("/Subtype")
                                    except Exception:
                                        continue
                                    if subtype == "/Image":
                                        width = xobj.get("/Width") or 0
                                        height = xobj.get("/Height") or 0
                                        try:
                                            area = int(width) * int(height)
                                        except Exception:
                                            area = 0
                                        if area >= MIN_SIGNIFICANT_IMAGE_AREA:
                                            has_images = True
                                            break
                                        logger.debug(
                                            "Ignoring small PDF image on page %d (%d pxÂ²)",
                                            page_num + 1,
                                            area,
                                        )
                except Exception:
                    # Si l'inspection Ã©choue, on ne bloque pas le flux
                    pass
        return '\n'.join(text), has_images
    
    loop = asyncio.get_event_loop()
    extracted_text, has_potential_images = await loop.run_in_executor(None, extract_pdf_text)
    
    # Si le PDF semble contenir des images ou peu de texte, utiliser Pixtral
    if has_potential_images or len(extracted_text.strip()) < settings.pdf_use_pixtral_threshold:
        logger.info(f"ðŸ“Š PDF nÃ©cessite Pixtral - Texte extrait: {len(extracted_text.strip())} caractÃ¨res (seuil: {settings.pdf_use_pixtral_threshold})")
        if has_potential_images:
            logger.info("ðŸ–¼ï¸ Images dÃ©tectÃ©es dans le PDF")
        
        try:
            pixtral_text = await _process_pdf_with_pixtral(
                file_path,
                max_pages=settings.pdf_max_pages_pixtral,
                progress_callback=progress_callback,
            )
            # Combiner les deux approches si on a du texte des deux cÃ´tÃ©s
            if extracted_text.strip() and pixtral_text.strip():
                logger.info(f"ðŸ”€ Combinaison extraction texte + Pixtral")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (Pixtral)",
                        "progress": 0.7,
                        "message": "Analyse visuelle terminÃ©e",
                    },
                )
                return (
                    "=== Analyse visuelle (Pixtral) ===\n"
                    f"{pixtral_text}\n\n"
                    "=== Texte extrait ===\n"
                    f"{extracted_text}"
                )
            elif pixtral_text.strip():
                logger.info(f"ðŸŽ¨ Utilisation Pixtral seul")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (Pixtral)",
                        "progress": 0.7,
                        "message": "Analyse visuelle terminÃ©e",
                    },
                )
                return pixtral_text
        except Exception as e:
            logger.error(f"âŒ Erreur traitement PDF avec Pixtral: {e}")
            # Fallback sur le texte extrait
    else:
        logger.info(f"ðŸ“ PDF traitÃ© avec extraction de texte simple ({len(extracted_text.strip())} caractÃ¨res)")
    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.6,
            "message": "Extraction du texte PDF terminÃ©e",
        },
    )
    return extracted_text

async def _process_docx_file(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Extrait le texte d'un fichier DOCX et traite les images embarquÃ©es"""

    def extract_docx_text() -> str:
        doc = docx.Document(file_path)
        text = []
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text.append(paragraph.text)
        return '\n'.join(text)

    loop = asyncio.get_event_loop()
    text_content = await loop.run_in_executor(None, extract_docx_text)

    image_sections: List[str] = []
    has_images = False

    try:
        with ZipFile(file_path, 'r') as archive:
            media_files = [name for name in archive.namelist() if name.startswith('word/media/')]
            if media_files:
                significant_images: List[tuple[str, bytes]] = []
                skipped_small = 0

                for name in media_files:
                    try:
                        data = archive.read(name)
                    except KeyError:
                        logger.warning(f"Image {name} introuvable dans l'archive DOCX")
                        continue

                    try:
                        with Image.open(io.BytesIO(data)) as pil_img:
                            width, height = pil_img.size
                            area = width * height
                    except Exception:
                        area = MIN_SIGNIFICANT_IMAGE_AREA  # Fallback: traiter

                    if area < MIN_SIGNIFICANT_IMAGE_AREA:
                        skipped_small += 1
                        logger.debug(
                            "Skipping small DOCX image %s (%d pxÂ²)",
                            name,
                            area,
                        )
                        continue

                    significant_images.append((name, data))

                total_images = len(significant_images)
                has_images = total_images > 0

                if total_images == 0:
                    logger.info("Aucune image significative dÃ©tectÃ©e dans le DOCX")
                else:
                    progress_start = 0.2
                    progress_end = 0.7
                    progress_span = max(progress_end - progress_start, 0.05)
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (Pixtral)",
                            "current": 0,
                            "total": total_images,
                            "progress": progress_start,
                            "message": f"Analyse des images (0/{total_images})",
                        },
                    )

                    with tempfile.TemporaryDirectory() as temp_dir:
                        temp_dir_path = Path(temp_dir)
                        for idx, (name, data) in enumerate(significant_images, start=1):
                            suffix = Path(name).suffix or '.png'
                            image_path = temp_dir_path / f"docx_image_{idx}{suffix}"

                            try:
                                async with aiofiles.open(image_path, 'wb') as img_file:
                                    await img_file.write(data)
                            except Exception as e:
                                logger.error(f"âŒ Impossible d'Ã©crire l'image DOCX {name}: {e}")
                                continue

                            try:
                                transcription = await _process_image_file_with_pixtral(
                                    image_path,
                                    progress_callback=progress_callback,
                                    position=idx,
                                    total=total_images,
                                )
                                if transcription and transcription.strip():
                                    image_sections.append(
                                        f"Image {idx} ({Path(name).name}):\n{transcription}"
                                    )
                                await _emit_progress(
                                    progress_callback,
                                    {
                                        "stage": "vision_analysis",
                                        "stage_label": "Analyse visuelle (Pixtral)",
                                        "current": idx,
                                        "total": total_images,
                                        "progress": progress_start + (idx / max(total_images, 1)) * progress_span,
                                        "message": f"Analyse des images ({idx}/{total_images})",
                                    },
                                )
                            except Exception as e:
                                logger.error(f"âŒ Erreur lors de l'analyse Pixtral de l'image DOCX {name}: {e}")

                if skipped_small:
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (Pixtral)",
                            "progress": progress_start,
                            "message": f"{skipped_small} image(s) ignorÃ©e(s) car trop petites",
                        },
                    )
    except Exception as e:
        logger.warning(f"âš ï¸ Impossible d'extraire les images du DOCX: {e}")

    if has_images and image_sections:
        await _emit_progress(
            progress_callback,
            {
                "stage": "vision_analysis",
                "stage_label": "Analyse visuelle (Pixtral)",
                "progress": 0.7,
                "message": "Analyse visuelle terminÃ©e",
            },
        )
        if text_content.strip():
            return (
                "=== Analyse visuelle (Pixtral) ===\n"
                + "\n\n".join(image_sections)
                + "\n\n=== Texte extrait ===\n"
                + text_content
            )
        return "\n\n".join(image_sections)

    await _emit_progress(
        progress_callback,
        {
            "stage": "text_extraction",
            "stage_label": "Extraction du texte",
            "progress": 0.6,
            "message": "Texte extrait",
        },
    )

    return text_content

async def _process_rtf_file(file_path: Path) -> str:
    """Traite un fichier RTF (simplifiÃ© - nÃ©cessiterait une lib spÃ©cialisÃ©e pour un support complet)"""
    # Pour l'instant, traiter comme texte brut
    # Dans un cas rÃ©el, utiliser striprtf ou python-rtf
    return await _process_text_file(file_path)

async def _process_image_file_with_pixtral(
    file_path: Path,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    position: Optional[int] = None,
    total: Optional[int] = None,
) -> str:
    """Utilise Pixtral pour analyser et transcrire le contenu d'une image"""
    from app.config import settings
    
    logger.info(f"ðŸŽ¨ DÃ©but analyse Pixtral pour: {file_path.name}")
    single_asset = position is None or total is None
    progress_start = 0.2 if single_asset else None
    progress_end = 0.7 if single_asset else None
    if single_asset:
        await _emit_progress(
            progress_callback,
            {
                "stage": "vision_analysis",
                "stage_label": "Analyse visuelle (Pixtral)",
                "current": 0,
                "total": 1,
                "progress": progress_start,
                "message": "Analyse visuelle de l'image",
            },
        )
    logger.info(f"ðŸ”§ Mode LLM: {settings.llm_mode}")
    
    # Encoder l'image en base64
    logger.info(f"ðŸ” Encodage de l'image en base64...")
    async with aiofiles.open(file_path, 'rb') as f:
        image_data = await f.read()
        base64_image = base64.b64encode(image_data).decode('utf-8')
    logger.info(f"âœ… Image encodÃ©e: {len(base64_image)} caractÃ¨res")
    
    # DÃ©terminer le type MIME de l'image
    ext = file_path.suffix.lower()
    mime_types = {
        '.png': 'image/png',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }
    mime_type = mime_types.get(ext, 'image/jpeg')
    
    # DÃ©terminer si on utilise le mode API ou local
    if settings.llm_mode == "local":
        # Mode local : utiliser vLLM avec Pixtral
        logger.info(f"ðŸš€ Utilisation de Pixtral local (vLLM)")
        from app.services.vllm_service import VLLMService
        
        try:
            vllm_service = VLLMService()
            prompt = (
                "Analyse cette image avec le plus de prÃ©cision possible. Commence par identifier le type de visuel "
                "(photo, illustration, capture d'Ã©cran, tableau, slide, document scannÃ©, etc.). "
                "Ensuite, retranscris mot pour mot tout le texte lisible. Pour un tableau ou un formulaire, "
                "restitue les en-tÃªtes et les valeurs cellule par cellule. Pour une capture d'Ã©cran, explique "
                "l'application ou le site montrÃ©, les sections visibles et le dÃ©roulÃ© exact de la conversation ou des "
                "donnÃ©es affichÃ©es. Pour un paysage ou une scÃ¨ne photo, dÃ©cris en dÃ©tail les Ã©lÃ©ments, leurs positions, "
                "les couleurs, l'ambiance, ainsi que toute information contextuelle implicite (moment de la journÃ©e, "
                "activitÃ© en cours, public visÃ©, etc.). Termine par un rÃ©sumÃ© synthÃ©tique et les informations clÃ©s Ã  "
                "retenir. Organise ta rÃ©ponse avec des sections claires (Type d'image, Texte exact, Description dÃ©taillÃ©e, "
                "RÃ©sumÃ©, Informations clÃ©s)."
            )
            
            result = await vllm_service.process_image_with_pixtral(base64_image, prompt)
            logger.info(f"âœ… Pixtral local a retournÃ© {len(result)} caractÃ¨res")
            logger.info(f"ðŸ“„ AperÃ§u: {result[:200]}...")
            await _emit_progress(
                progress_callback,
                {
                    "stage": "vision_analysis",
                    "stage_label": "Analyse visuelle (Pixtral)",
                    "current": position or 1,
                    "total": total or 1,
                    "progress": progress_end,
                    "message": "Analyse visuelle terminÃ©e",
                },
            )
            return result
            
        except Exception as e:
            logger.error(f"âŒ Erreur Pixtral local: {str(e)}", exc_info=True)
            return f"Erreur lors de l'analyse de l'image avec Pixtral local: {str(e)}"
    else:
        # Mode API : utiliser Mistral API
        logger.info(f"ðŸš€ Appel API Pixtral avec modÃ¨le: {settings.pixtral_model}")
        # Construire l'URL data de l'image
        image_url = f"data:{mime_type};base64,{base64_image}"
        
        try:
            response = await _call_pixtral_api(
                [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """Analyse cette image et fais une transcription complÃ¨te et dÃ©taillÃ©e de son contenu. 
                                Si l'image contient du texte, transcris-le exactement. 
                                Si l'image contient des Ã©lÃ©ments visuels (graphiques, schÃ©mas, photos), dÃ©cris-les de maniÃ¨re dÃ©taillÃ©e.
                                Si c'est une capture d'Ã©cran, dÃ©cris l'interface et transcris tout le texte visible.
                                Organise ta rÃ©ponse de maniÃ¨re structurÃ©e."""
                            },
                            {
                                "type": "image_url",
                                "image_url": image_url
                            }
                        ]
                    }
                ]
            )
            
            # Extraire la transcription de la rÃ©ponse
            if response.choices and len(response.choices) > 0:
                result = response.choices[0].message.content
                logger.info(f"âœ… Pixtral API a retournÃ© {len(result)} caractÃ¨res")
                logger.info(f"ðŸ“„ AperÃ§u: {result[:200]}...")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (Pixtral)",
                        "current": position or 1,
                        "total": total or 1,
                        "progress": progress_end,
                        "message": "Analyse visuelle terminÃ©e",
                    },
                )
                return result
            else:
                logger.error("âŒ Pixtral API n'a retournÃ© aucune rÃ©ponse")
                return "Erreur: Aucune transcription gÃ©nÃ©rÃ©e par Pixtral"
            
        except Exception as e:
            logger.error(f"âŒ Erreur Pixtral: {str(e)}", exc_info=True)
            return f"Erreur lors de l'analyse de l'image avec Pixtral: {str(e)}"

async def _process_pdf_with_pixtral(
    file_path: Path,
    max_pages: int = 0,
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
) -> str:
    """Convertit les pages PDF en images et les analyse avec Pixtral"""
    from app.config import settings
    
    logger.info(f"ðŸ“‘ DÃ©but traitement PDF avec Pixtral: {file_path.name}")
    logger.info(f"ðŸ”§ Mode LLM: {settings.llm_mode}")
    
    # Initialiser le service appropriÃ© selon le mode
    if settings.llm_mode == "local":
        from app.services.vllm_service import VLLMService
        vllm_service = VLLMService()
        logger.info("ðŸ“Š Utilisation de Pixtral local pour PDF")
    else:
        logger.info(f"ðŸ“Š Utilisation de Pixtral API pour PDF (modÃ¨le: {settings.pixtral_model})")
    
    results = []
    
    # CrÃ©er un dossier temporaire pour les images
    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            # Convertir le PDF en images (limitÃ©es Ã  max_pages pour Ã©viter de traiter des PDFs Ã©normes)
            if max_pages > 0:
                logger.info(f"ðŸ–¼ï¸ Conversion PDF en images (max {max_pages} pages)...")
                convert_kwargs = {"first_page": 1, "last_page": max_pages, "dpi": 150}
            else:
                logger.info("ðŸ–¼ï¸ Conversion PDF en images (toutes les pages)...")
                convert_kwargs = {"dpi": 150}
            images = await asyncio.to_thread(
                convert_from_path,
                str(file_path),
                **convert_kwargs,
            )
            total_pages = len(images)
            logger.info(f"âœ… {total_pages} pages converties")
            progress_start = 0.2
            progress_end = 0.7
            progress_span = max(progress_end - progress_start, 0.05)
            await _emit_progress(
                progress_callback,
                {
                    "stage": "vision_analysis",
                    "stage_label": "Analyse visuelle (Pixtral)",
                    "current": 0,
                    "total": total_pages,
                    "progress": progress_start,
                    "message": f"Analyse des pages (0/{total_pages})",
                },
            )
            
            # Traiter chaque page avec Pixtral
            for i, image in enumerate(images):
                logger.info(f"ðŸ“„ Traitement page {i+1}/{total_pages}...")
                await _emit_progress(
                    progress_callback,
                    {
                        "stage": "vision_analysis",
                        "stage_label": "Analyse visuelle (Pixtral)",
                        "current": i,
                        "total": total_pages,
                        "progress": progress_start + (i / max(total_pages, 1)) * progress_span,
                        "message": f"Analyse de la page {i+1}/{total_pages}",
                    },
                )
                # Sauvegarder temporairement l'image
                temp_image_path = Path(temp_dir) / f"page_{i+1}.png"
                await asyncio.to_thread(image.save, str(temp_image_path), 'PNG')
                
                # Encoder en base64
                async with aiofiles.open(temp_image_path, 'rb') as f:
                    image_data = await f.read()
                    base64_image = base64.b64encode(image_data).decode('utf-8')
                
                # Analyser avec Pixtral (API ou local selon le mode)
                try:
                    prompt = (
                        f"Analyse la page {i+1} de ce PDF en suivant les directives suivantes : identifie d'abord le type de "
                        "contenu visuel principal (document imprimÃ©, capture d'Ã©cran, diapositive, photo, tableau, etc.). "
                        "Transcris ensuite mot pour mot tout le texte lisible. Pour les tableaux, restitue les colonnes et "
                        "les lignes avec leurs valeurs exactes. Pour les captures d'Ã©cran, explique le contexte (application, "
                        "sites ou interlocuteurs) et dÃ©taille la conversation ou les donnÃ©es affichÃ©es. Pour les photos ou "
                        "illustrations, dÃ©cris prÃ©cisÃ©ment les Ã©lÃ©ments visibles, leurs positions, couleurs, ambiance et "
                        "intention probable. Termine la page par un rÃ©sumÃ© synthÃ©tique et une liste d'informations clÃ©s Ã  "
                        "retenir. Structure ta rÃ©ponse avec les sections : Type de contenu, Texte exact, Description "
                        "dÃ©taillÃ©e, RÃ©sumÃ©, Informations clÃ©s."
                    )
                    
                    page_content: Optional[str] = None

                    if settings.llm_mode == "local":
                        # Mode local : utiliser vLLM
                        page_content = await vllm_service.process_image_with_pixtral(base64_image, prompt)
                    else:
                        # Mode API : utiliser Mistral
                        image_url = f"data:image/png;base64,{base64_image}"
                        response = await _call_pixtral_api(
                            [
                                {
                                    "role": "user",
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": prompt
                                        },
                                        {
                                            "type": "image_url",
                                            "image_url": image_url
                                        }
                                    ]
                                }
                            ]
                        )
                        if response.choices and len(response.choices) > 0:
                            page_content = response.choices[0].message.content

                    if page_content:
                        results.append(f"\n=== Page {i+1} ===\n{page_content}")
                    else:
                        logger.warning("Pixtral n'a renvoyÃ© aucun contenu pour la page %d", i + 1)
                        raise RuntimeError("La rÃ©ponse Pixtral est vide")

                except Exception as e:
                    results.append(f"\n=== Page {i+1} ===\nErreur lors de l'analyse: {str(e)}")
                finally:
                    current_page = min(i + 1, total_pages)
                    await _emit_progress(
                        progress_callback,
                        {
                            "stage": "vision_analysis",
                            "stage_label": "Analyse visuelle (Pixtral)",
                            "current": current_page,
                            "total": total_pages,
                            "progress": progress_start + (current_page / max(total_pages, 1)) * progress_span,
                            "message": f"Analyse des pages ({current_page}/{total_pages})",
                        },
                    )
                
                # Limiter pour Ã©viter de surcharger l'API
                if max_pages > 0 and i >= max_pages - 1:
                    if len(images) > max_pages:
                        results.append(f"\n\n[Note: PDF contient {len(images)} pages, seules les {max_pages} premiÃ¨res ont Ã©tÃ© analysÃ©es]")
                    break
                    
        except Exception as e:
            return f"Erreur lors de la conversion PDF en images: {str(e)}"

    await _emit_progress(
        progress_callback,
        {
            "stage": "vision_analysis",
            "stage_label": "Analyse visuelle (Pixtral)",
            "progress": 0.7,
            "message": "Analyse visuelle terminÃ©e",
        },
    )
    
    return '\n'.join(results)

def estimate_token_count(text: str) -> int:
    """
    Estime le nombre de tokens dans un texte
    Approximation: ~4 caractÃ¨res par token en moyenne
    """
    return len(text) // 4

def truncate_to_token_limit(text: str, max_tokens: int = 2000) -> str:
    """
    Tronque un texte pour respecter une limite de tokens
    """
    estimated_chars = max_tokens * 4
    if len(text) <= estimated_chars:
        return text
    
    # Tronquer en gardant un peu de marge
    truncated = text[:estimated_chars - 100]
    
    # Essayer de couper Ã  la fin d'une phrase
    last_period = truncated.rfind('.')
    last_newline = truncated.rfind('\n')
    
    cut_point = max(last_period, last_newline)
    if cut_point > estimated_chars // 2:  # Si on trouve un point de coupure raisonnable
        truncated = truncated[:cut_point + 1]
    
    return truncated + "\n\n[Document tronquÃ©...]"
